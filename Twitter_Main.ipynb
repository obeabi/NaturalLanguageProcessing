{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterSentiment_Main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obHZKRDhZFnc"
      },
      "source": [
        "# Sentiment140 - A Twitter Sentiment Analysis Tool\r\n",
        "# Written by Abiola Obembe\r\n",
        "## Date: 2020-12-\r\n",
        "\r\n",
        "\r\n",
        "Abstract\r\n",
        "The data is a CSV with emoticons removed. Data file format has 6 fields:\r\n",
        "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\r\n",
        "1 - the id of the tweet (2087)\r\n",
        "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\r\n",
        "3 - the query (lyx). If there is no query, then this value is NO_QUERY.\r\n",
        "4 - the user that tweeted (robotickilldozr)\r\n",
        "5 - the text of the tweet (Lyx is cool)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j5hQSKsDo2P"
      },
      "source": [
        "# Tokenization library installation\r\n",
        "!pip install -q tensorflow-text"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEBdKsZgZXtm"
      },
      "source": [
        "## Step 1: Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW1k6_EaZVpb",
        "outputId": "28ab48da-27f2-4d38-8ff8-c2e3e5c6ee33"
      },
      "source": [
        "#Import libraries\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import math\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "#from nltk.corpus import stopwords\r\n",
        "#from nltk.stem.porter import PorterStemmer\r\n",
        "# Mount data from google drive\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "\r\n",
        "# Tensorflow v2\r\n",
        "\r\n",
        "try:\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow_text as text\r\n",
        "print(\"The tensorflow version is :\", tf.__version__)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Dependencies installed succesffuly!\")\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorflow version is : 2.3.0\n",
            "Dependencies installed succesffuly!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22tPdO8XbDSp"
      },
      "source": [
        "## Step 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCQSzc2ObGqU",
        "outputId": "47fe052e-b039-46ee-af02-4cf3020b625b"
      },
      "source": [
        "# Mount data from google drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "2w3uzhfhajvD",
        "outputId": "c5fa0332-561f-4e3f-c4aa-4d7960185690"
      },
      "source": [
        "# Load data files\r\n",
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\r\n",
        "\r\n",
        "train_data = pd.read_csv(\r\n",
        "    \"/content/drive/MyDrive/DS_Projects/CNN_4_NLP/traindata.csv\",error_bad_lines=False,\r\n",
        "    header=None,names=cols,engine=\"python\",encoding=\"latin1\",nrows = 100)\r\n",
        "\r\n",
        "test_data = pd.read_csv(\r\n",
        "    \"/content/drive/MyDrive/DS_Projects/CNN_4_NLP/testdata.csv\",error_bad_lines=False,\r\n",
        "    header=None, names=cols,engine=\"python\",encoding=\"latin1\")\r\n",
        "\r\n",
        "\r\n",
        "print(\"Training set :\", train_data.shape )\r\n",
        "print(\"Test set :\", test_data.shape)\r\n",
        "\r\n",
        "train_data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set : (100, 6)\n",
            "Test set : (498, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "2          0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3          0  ...    my whole body feels itchy and like its on fire \n",
              "4          0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "tuh_09R0kSwS",
        "outputId": "518e98dd-5d7d-4f07-ff31-8bc4843bfbe9"
      },
      "source": [
        "# clean data\r\n",
        "train_data.drop(['id','date', 'query','user'], axis = 1, inplace= True)\r\n",
        "train_data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOlvE28TnnTN",
        "outputId": "8e944a1e-6fc3-4d1b-903d-c6f9ffd54e41"
      },
      "source": [
        "# Examine sentiment data labels\r\n",
        "train_data['sentiment'].value_counts()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    100\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIeIpI3jk5Sc"
      },
      "source": [
        "# Function to clean\r\n",
        "def clean_tweet(tweet):\r\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\r\n",
        "    # Removing the @\r\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\r\n",
        "    # Removing the URL links\r\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\r\n",
        "    # Keeping only letters\r\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\r\n",
        "    # Removing additional whitespaces\r\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\r\n",
        "    tweet = tweet.lower()\r\n",
        "    \r\n",
        "    return tweet"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf0AwVwWlB5_"
      },
      "source": [
        "# apply function on dataset\r\n",
        "data_train_clean = [ clean_tweet(tweet)  for tweet in train_data.text]\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al2XjcBqlmLv",
        "outputId": "ed1ebb8d-f7b4-47f1-e92c-aaaeacd57b29"
      },
      "source": [
        "# Evaluate the sentiment column\r\n",
        "set(train_data.sentiment.values)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HPurBPrl5ni",
        "outputId": "e2ab221a-4fec-43b6-9ec3-71e66458e4c1"
      },
      "source": [
        "# Let's set the sentiment values labelled 4 as 1\r\n",
        "data_labels = train_data.sentiment.values\r\n",
        "data_labels[data_labels == 4] = 1\r\n",
        "set(data_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJSMvB-WoPy5"
      },
      "source": [
        "# Tokenization\r\n",
        "#tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(data_train_clean, target_vocab_size=2**10)\r\n",
        "#data_inputs = [tokenizer.encode(sentence) for sentence in data_train_clean]\r\n",
        "from keras.preprocessing.text import Tokenizer  \r\n",
        "tokenizer = Tokenizer(num_words=5000)\r\n",
        "tokenizer.fit_on_texts(data_train_clean)\r\n",
        "#data_inputs = [tokenizer.texts_to_sequences(sentence) for sentence in data_train_clean]\r\n",
        "data_inputs = tokenizer.texts_to_sequences(data_train_clean)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RevtWP6eKMiS",
        "outputId": "53f04ec1-05a1-4fc5-cca1-aac6a2fff903"
      },
      "source": [
        "data_inputs"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[100, 101, 6, 173, 7, 174, 51, 175, 176, 15, 177, 23, 3, 34, 8, 178],\n",
              " [9,\n",
              "  179,\n",
              "  11,\n",
              "  180,\n",
              "  52,\n",
              "  181,\n",
              "  182,\n",
              "  183,\n",
              "  102,\n",
              "  184,\n",
              "  8,\n",
              "  4,\n",
              "  185,\n",
              "  70,\n",
              "  53,\n",
              "  6,\n",
              "  186,\n",
              "  103,\n",
              "  44,\n",
              "  104,\n",
              "  187],\n",
              " [1, 188, 189, 190, 10, 2, 191, 192, 3, 193, 2, 194, 71, 28, 15, 195],\n",
              " [5, 105, 106, 196, 197, 4, 29, 72, 35, 198],\n",
              " [30,\n",
              "  45,\n",
              "  12,\n",
              "  199,\n",
              "  16,\n",
              "  73,\n",
              "  31,\n",
              "  107,\n",
              "  36,\n",
              "  74,\n",
              "  1,\n",
              "  54,\n",
              "  200,\n",
              "  1,\n",
              "  52,\n",
              "  24,\n",
              "  7,\n",
              "  73,\n",
              "  201,\n",
              "  75],\n",
              " [12, 2, 105, 202],\n",
              " [55, 6, 108],\n",
              " [56,\n",
              "  109,\n",
              "  46,\n",
              "  30,\n",
              "  24,\n",
              "  203,\n",
              "  204,\n",
              "  6,\n",
              "  110,\n",
              "  76,\n",
              "  6,\n",
              "  110,\n",
              "  111,\n",
              "  31,\n",
              "  205,\n",
              "  206,\n",
              "  207,\n",
              "  7],\n",
              " [208, 209, 77, 57, 18, 8],\n",
              " [210, 13, 211],\n",
              " [212, 112, 14, 213, 214, 45, 215],\n",
              " [1, 20, 216, 217, 5, 218],\n",
              " [1, 219, 220, 3, 78, 8, 4, 1, 79, 2, 221, 222, 21, 223],\n",
              " [8, 8, 224, 225, 36, 1, 80, 81, 7, 82, 226, 3, 13, 227],\n",
              " [1,\n",
              "  228,\n",
              "  229,\n",
              "  2,\n",
              "  230,\n",
              "  17,\n",
              "  1,\n",
              "  57,\n",
              "  18,\n",
              "  6,\n",
              "  231,\n",
              "  12,\n",
              "  37,\n",
              "  58,\n",
              "  232,\n",
              "  233,\n",
              "  20,\n",
              "  6,\n",
              "  234],\n",
              " [1, 113, 1, 51, 3, 78, 8, 32, 7, 1, 47, 7, 4, 59, 21, 2, 235],\n",
              " [236,\n",
              "  237,\n",
              "  238,\n",
              "  114,\n",
              "  239,\n",
              "  13,\n",
              "  240,\n",
              "  3,\n",
              "  78,\n",
              "  35,\n",
              "  241,\n",
              "  242,\n",
              "  9,\n",
              "  243,\n",
              "  244,\n",
              "  12,\n",
              "  28,\n",
              "  25],\n",
              " [38, 3, 245, 246],\n",
              " [247, 248, 115, 249, 3, 24, 250, 116, 2, 251],\n",
              " [60, 252, 117, 7, 253, 28, 15, 2, 254, 255, 256],\n",
              " [1, 21, 28, 257, 15, 2, 23, 22, 57, 83, 61, 258],\n",
              " [39,\n",
              "  15,\n",
              "  5,\n",
              "  259,\n",
              "  260,\n",
              "  13,\n",
              "  4,\n",
              "  261,\n",
              "  3,\n",
              "  262,\n",
              "  32,\n",
              "  263,\n",
              "  16,\n",
              "  264,\n",
              "  265,\n",
              "  44,\n",
              "  17,\n",
              "  118,\n",
              "  30,\n",
              "  46,\n",
              "  266],\n",
              " [267, 1, 268, 7, 6, 269, 17, 1, 270, 8],\n",
              " [84, 271, 9, 12, 62, 53, 1, 63, 272],\n",
              " [273, 64, 16, 40],\n",
              " [1, 48, 85, 1, 18, 3, 274, 4, 275, 119, 49],\n",
              " [20, 62, 3, 70, 276, 3, 65, 277, 278, 279, 4, 13],\n",
              " [120, 26, 25, 47, 280],\n",
              " [281, 111, 11, 121, 4, 122, 1, 66, 34, 8, 123, 22, 121, 66, 83, 107, 123],\n",
              " [282, 283, 284, 9, 2, 285, 84, 286, 287, 13, 124, 288, 46],\n",
              " [289, 290, 5, 291, 35, 292, 25, 1, 18, 3, 125, 6, 126, 39],\n",
              " [1,\n",
              "  86,\n",
              "  3,\n",
              "  71,\n",
              "  3,\n",
              "  293,\n",
              "  294,\n",
              "  4,\n",
              "  295,\n",
              "  17,\n",
              "  296,\n",
              "  30,\n",
              "  297,\n",
              "  75,\n",
              "  1,\n",
              "  87,\n",
              "  88,\n",
              "  62,\n",
              "  3,\n",
              "  2,\n",
              "  39,\n",
              "  14,\n",
              "  298,\n",
              "  14,\n",
              "  87,\n",
              "  58],\n",
              " [79,\n",
              "  299,\n",
              "  14,\n",
              "  21,\n",
              "  89,\n",
              "  300,\n",
              "  40,\n",
              "  17,\n",
              "  301,\n",
              "  11,\n",
              "  8,\n",
              "  25,\n",
              "  9,\n",
              "  12,\n",
              "  302,\n",
              "  14,\n",
              "  2,\n",
              "  303,\n",
              "  4,\n",
              "  67,\n",
              "  14,\n",
              "  2,\n",
              "  304],\n",
              " [305, 1, 116, 7, 19, 74, 54, 1, 47, 7],\n",
              " [1, 70, 5, 306, 307, 3, 65, 16, 127],\n",
              " [122,\n",
              "  31,\n",
              "  90,\n",
              "  4,\n",
              "  308,\n",
              "  89,\n",
              "  128,\n",
              "  309,\n",
              "  14,\n",
              "  2,\n",
              "  310,\n",
              "  311,\n",
              "  1,\n",
              "  21,\n",
              "  19,\n",
              "  90,\n",
              "  3,\n",
              "  312,\n",
              "  4,\n",
              "  313,\n",
              "  129,\n",
              "  2,\n",
              "  314,\n",
              "  29,\n",
              "  6,\n",
              "  315,\n",
              "  91,\n",
              "  25],\n",
              " [130,\n",
              "  316,\n",
              "  131,\n",
              "  2,\n",
              "  317,\n",
              "  318,\n",
              "  12,\n",
              "  6,\n",
              "  132,\n",
              "  23,\n",
              "  4,\n",
              "  130,\n",
              "  92,\n",
              "  319,\n",
              "  10,\n",
              "  29,\n",
              "  320,\n",
              "  68,\n",
              "  321],\n",
              " [50, 91, 46, 322, 54, 323],\n",
              " [1, 33, 81, 72, 324, 1, 33, 41, 1, 133, 86, 3, 93, 38, 2, 325, 14, 326],\n",
              " [91, 64, 67, 134, 94, 327, 64, 328, 23, 101, 329, 330, 102, 1, 47, 5, 331],\n",
              " [37, 33, 332, 29, 135, 49, 44, 17, 51, 3, 333, 3, 10, 334, 335, 336],\n",
              " [337,\n",
              "  2,\n",
              "  338,\n",
              "  10,\n",
              "  2,\n",
              "  339,\n",
              "  35,\n",
              "  5,\n",
              "  340,\n",
              "  2,\n",
              "  76,\n",
              "  39,\n",
              "  341,\n",
              "  136,\n",
              "  342,\n",
              "  15,\n",
              "  13,\n",
              "  3,\n",
              "  112,\n",
              "  5,\n",
              "  137],\n",
              " [26, 26, 26, 1, 33, 93, 36, 17, 1, 48, 84, 138, 1, 343, 65, 4, 1, 42, 52],\n",
              " [100, 1, 344, 113, 1, 21, 75, 3, 24, 7, 345, 346, 120, 26, 11, 1, 139, 8],\n",
              " [347,\n",
              "  140,\n",
              "  20,\n",
              "  348,\n",
              "  38,\n",
              "  11,\n",
              "  349,\n",
              "  350,\n",
              "  106,\n",
              "  141,\n",
              "  142,\n",
              "  59,\n",
              "  26,\n",
              "  5,\n",
              "  137,\n",
              "  351,\n",
              "  10,\n",
              "  11,\n",
              "  352],\n",
              " [353, 31, 354, 10, 7, 32, 143, 144, 17, 11, 104, 355, 356, 46, 10, 13, 4, 7],\n",
              " [20,\n",
              "  357,\n",
              "  5,\n",
              "  358,\n",
              "  359,\n",
              "  35,\n",
              "  5,\n",
              "  360,\n",
              "  8,\n",
              "  361,\n",
              "  29,\n",
              "  2,\n",
              "  362,\n",
              "  9,\n",
              "  42,\n",
              "  363,\n",
              "  27,\n",
              "  364,\n",
              "  42,\n",
              "  365,\n",
              "  366,\n",
              "  145,\n",
              "  367,\n",
              "  4,\n",
              "  368],\n",
              " [60, 369, 21, 370, 371, 372, 373, 3, 374, 3, 6, 146, 375, 8],\n",
              " [9, 376, 26, 38, 377, 4, 378, 379, 49],\n",
              " [60, 31, 22, 50, 1, 57, 41, 38, 11, 147, 380],\n",
              " [148,\n",
              "  381,\n",
              "  382,\n",
              "  383,\n",
              "  384,\n",
              "  385,\n",
              "  386,\n",
              "  387,\n",
              "  388,\n",
              "  389,\n",
              "  390,\n",
              "  42,\n",
              "  391,\n",
              "  10,\n",
              "  148,\n",
              "  149,\n",
              "  27],\n",
              " [392,\n",
              "  393,\n",
              "  15,\n",
              "  394,\n",
              "  95,\n",
              "  7,\n",
              "  87,\n",
              "  18,\n",
              "  3,\n",
              "  395,\n",
              "  22,\n",
              "  1,\n",
              "  96,\n",
              "  24,\n",
              "  5,\n",
              "  396,\n",
              "  397,\n",
              "  150,\n",
              "  398,\n",
              "  2,\n",
              "  399,\n",
              "  6,\n",
              "  151],\n",
              " [152, 400, 4, 401, 27, 402, 403, 19, 109, 3, 404],\n",
              " [405,\n",
              "  406,\n",
              "  407,\n",
              "  408,\n",
              "  6,\n",
              "  409,\n",
              "  410,\n",
              "  411,\n",
              "  412,\n",
              "  413,\n",
              "  4,\n",
              "  25,\n",
              "  1,\n",
              "  414,\n",
              "  2,\n",
              "  415,\n",
              "  15,\n",
              "  2,\n",
              "  416],\n",
              " [1, 55, 6, 108],\n",
              " [12,\n",
              "  153,\n",
              "  97,\n",
              "  77,\n",
              "  27,\n",
              "  76,\n",
              "  11,\n",
              "  77,\n",
              "  27,\n",
              "  417,\n",
              "  53,\n",
              "  61,\n",
              "  53,\n",
              "  1,\n",
              "  86,\n",
              "  3,\n",
              "  1,\n",
              "  154,\n",
              "  41,\n",
              "  96,\n",
              "  418,\n",
              "  419,\n",
              "  420,\n",
              "  421,\n",
              "  50,\n",
              "  422],\n",
              " [1, 48, 85, 11, 423],\n",
              " [1,\n",
              "  18,\n",
              "  6,\n",
              "  26,\n",
              "  138,\n",
              "  11,\n",
              "  424,\n",
              "  9,\n",
              "  12,\n",
              "  62,\n",
              "  3,\n",
              "  155,\n",
              "  49,\n",
              "  1,\n",
              "  425,\n",
              "  426,\n",
              "  58,\n",
              "  427,\n",
              "  41,\n",
              "  68,\n",
              "  428,\n",
              "  429,\n",
              "  430,\n",
              "  431,\n",
              "  95,\n",
              "  2,\n",
              "  432,\n",
              "  433],\n",
              " [434, 435, 40],\n",
              " [436,\n",
              "  80,\n",
              "  43,\n",
              "  437,\n",
              "  3,\n",
              "  1,\n",
              "  79,\n",
              "  43,\n",
              "  117,\n",
              "  156,\n",
              "  14,\n",
              "  438,\n",
              "  439,\n",
              "  440,\n",
              "  43,\n",
              "  142,\n",
              "  13,\n",
              "  157,\n",
              "  3,\n",
              "  441,\n",
              "  442,\n",
              "  443,\n",
              "  158],\n",
              " [1, 47, 5, 444, 45, 28, 15, 445, 446, 447, 18, 7, 448, 449, 35, 2, 450],\n",
              " [20, 451, 2, 452, 151, 15, 67],\n",
              " [2, 453, 9, 454, 17, 12, 10, 13],\n",
              " [159, 58, 118, 82, 455, 3, 456, 2, 457, 458, 459, 147, 4, 25, 1, 82, 114],\n",
              " [1, 63, 160, 6, 460, 23, 19, 69, 2, 461, 462, 14, 40, 16, 74],\n",
              " [19,\n",
              "  69,\n",
              "  1,\n",
              "  66,\n",
              "  92,\n",
              "  463,\n",
              "  1,\n",
              "  464,\n",
              "  5,\n",
              "  144,\n",
              "  4,\n",
              "  52,\n",
              "  133,\n",
              "  465,\n",
              "  5,\n",
              "  161,\n",
              "  466,\n",
              "  467,\n",
              "  468,\n",
              "  469],\n",
              " [470, 129, 3, 103, 40],\n",
              " [471, 472, 30, 162, 59, 14, 2, 473, 9, 474, 475, 54, 476, 477, 89, 128],\n",
              " [12, 478, 24, 7, 163],\n",
              " [479, 480, 1, 481, 2, 482, 483, 23, 44],\n",
              " [60,\n",
              "  484,\n",
              "  485,\n",
              "  1,\n",
              "  154,\n",
              "  37,\n",
              "  486,\n",
              "  16,\n",
              "  487,\n",
              "  488,\n",
              "  98,\n",
              "  489,\n",
              "  56,\n",
              "  1,\n",
              "  490,\n",
              "  7,\n",
              "  50,\n",
              "  31,\n",
              "  22,\n",
              "  491,\n",
              "  16,\n",
              "  11,\n",
              "  1,\n",
              "  55,\n",
              "  6,\n",
              "  492,\n",
              "  49],\n",
              " [31,\n",
              "  153,\n",
              "  150,\n",
              "  164,\n",
              "  1,\n",
              "  55,\n",
              "  3,\n",
              "  165,\n",
              "  166,\n",
              "  28,\n",
              "  32,\n",
              "  7,\n",
              "  4,\n",
              "  2,\n",
              "  493,\n",
              "  94,\n",
              "  494,\n",
              "  16,\n",
              "  495],\n",
              " [1, 37, 48, 59, 119, 496, 5, 497, 498, 9, 499, 12, 500],\n",
              " [134,\n",
              "  501,\n",
              "  44,\n",
              "  21,\n",
              "  502,\n",
              "  503,\n",
              "  504,\n",
              "  505,\n",
              "  4,\n",
              "  506,\n",
              "  507,\n",
              "  508,\n",
              "  4,\n",
              "  509,\n",
              "  510,\n",
              "  511,\n",
              "  80,\n",
              "  12,\n",
              "  512,\n",
              "  513,\n",
              "  167,\n",
              "  514,\n",
              "  515],\n",
              " [36, 66, 7, 155, 5, 516],\n",
              " [30, 517, 5, 161, 518, 29, 519],\n",
              " [5,\n",
              "  520,\n",
              "  9,\n",
              "  521,\n",
              "  38,\n",
              "  160,\n",
              "  522,\n",
              "  523,\n",
              "  524,\n",
              "  4,\n",
              "  525,\n",
              "  92,\n",
              "  157,\n",
              "  3,\n",
              "  24,\n",
              "  143,\n",
              "  526,\n",
              "  527,\n",
              "  528,\n",
              "  9,\n",
              "  42,\n",
              "  529],\n",
              " [30, 126, 530, 531, 532],\n",
              " [1, 41, 5, 533, 27, 168, 95, 534],\n",
              " [535, 36, 98, 11, 43, 29, 22, 61, 96, 125, 7, 22, 536, 14, 6, 537, 538, 124],\n",
              " [65, 163, 1, 20, 48, 539, 540, 4, 24, 7, 40, 10, 2, 127],\n",
              " [20, 51, 541, 542, 543, 544, 37, 27, 545, 546, 1, 156, 547, 4, 169, 10, 548],\n",
              " [549, 2, 550],\n",
              " [13, 19, 551],\n",
              " [552, 1, 33, 18, 167, 553, 5, 554, 9, 555],\n",
              " [63,\n",
              "  6,\n",
              "  556,\n",
              "  16,\n",
              "  2,\n",
              "  557,\n",
              "  558,\n",
              "  17,\n",
              "  559,\n",
              "  11,\n",
              "  560,\n",
              "  63,\n",
              "  6,\n",
              "  168,\n",
              "  561,\n",
              "  73,\n",
              "  23,\n",
              "  45,\n",
              "  20,\n",
              "  135,\n",
              "  562,\n",
              "  19],\n",
              " [56, 139, 131, 16, 2, 146, 563, 564],\n",
              " [5,\n",
              "  565,\n",
              "  566,\n",
              "  1,\n",
              "  567,\n",
              "  99,\n",
              "  2,\n",
              "  568,\n",
              "  136,\n",
              "  569,\n",
              "  3,\n",
              "  34,\n",
              "  32,\n",
              "  8,\n",
              "  99,\n",
              "  22,\n",
              "  45,\n",
              "  166,\n",
              "  1,\n",
              "  83,\n",
              "  8,\n",
              "  570,\n",
              "  571],\n",
              " [36, 9, 8, 115, 2, 572, 573],\n",
              " [50, 574, 5, 575, 576, 13, 19, 577, 578, 140, 164, 25, 579, 580, 581],\n",
              " [1, 170, 18, 169, 68, 582, 85, 149, 583, 584, 14, 5, 585, 586, 64, 14, 587],\n",
              " [588, 5, 88, 23, 33, 93, 97, 34],\n",
              " [589, 590, 2, 591],\n",
              " [592,\n",
              "  10,\n",
              "  13,\n",
              "  593,\n",
              "  2,\n",
              "  594,\n",
              "  9,\n",
              "  595,\n",
              "  3,\n",
              "  165,\n",
              "  596,\n",
              "  16,\n",
              "  5,\n",
              "  152,\n",
              "  597,\n",
              "  598,\n",
              "  599,\n",
              "  171,\n",
              "  97,\n",
              "  6,\n",
              "  600,\n",
              "  4,\n",
              "  1,\n",
              "  42,\n",
              "  18,\n",
              "  6,\n",
              "  601],\n",
              " [602,\n",
              "  34,\n",
              "  43,\n",
              "  37,\n",
              "  603,\n",
              "  141,\n",
              "  32,\n",
              "  604,\n",
              "  99,\n",
              "  2,\n",
              "  605,\n",
              "  27,\n",
              "  19,\n",
              "  606,\n",
              "  43,\n",
              "  170,\n",
              "  41,\n",
              "  607,\n",
              "  68,\n",
              "  608,\n",
              "  98,\n",
              "  609],\n",
              " [610, 9, 6, 90, 611, 612],\n",
              " [22,\n",
              "  613,\n",
              "  614,\n",
              "  615,\n",
              "  71,\n",
              "  616,\n",
              "  171,\n",
              "  94,\n",
              "  12,\n",
              "  159,\n",
              "  617,\n",
              "  72,\n",
              "  618,\n",
              "  1,\n",
              "  619,\n",
              "  88,\n",
              "  620,\n",
              "  34,\n",
              "  61,\n",
              "  17,\n",
              "  621,\n",
              "  158],\n",
              " [56, 1, 622, 623, 39, 15, 5, 624, 625, 19, 69, 8, 626, 2, 39, 10, 162],\n",
              " [7, 33, 627, 13, 81, 4, 1, 67, 10, 7],\n",
              " [6,\n",
              "  69,\n",
              "  172,\n",
              "  10,\n",
              "  2,\n",
              "  628,\n",
              "  629,\n",
              "  630,\n",
              "  4,\n",
              "  631,\n",
              "  632,\n",
              "  2,\n",
              "  172,\n",
              "  28,\n",
              "  32,\n",
              "  633,\n",
              "  145,\n",
              "  21,\n",
              "  132]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I59hcIAkseiY"
      },
      "source": [
        "# Padding\r\n",
        "MAX_LEN = max([len(sentence) for sentence in data_inputs])\r\n",
        "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\r\n",
        "                                                            value=0,\r\n",
        "                                                            padding=\"post\",\r\n",
        "                                                            maxlen=MAX_LEN)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH2ISVcToJ_M",
        "outputId": "38065f98-7c5e-4b6f-915b-6c956683212a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_inputs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[100, 101,   6, ...,   0,   0,   0],\n",
              "       [  9, 179,  11, ...,   0,   0,   0],\n",
              "       [  1, 188, 189, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 56,   1, 622, ...,   0,   0,   0],\n",
              "       [  7,  33, 627, ...,   0,   0,   0],\n",
              "       [  6,  69, 172, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW9sfeEVtbmE",
        "outputId": "15de0454-b3fb-464e-b2a6-9400807d9389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# Split dataset into test and train set (due to orderd nature of traget values 0 and 1)\r\n",
        "test_idx = np.random.randint(0, 800000, 8000)\r\n",
        "test_idx = np.concatenate((test_idx, test_idx+800000))\r\n",
        "test_inputs = data_inputs[test_idx]\r\n",
        "test_labels = data_labels[test_idx]\r\n",
        "train_inputs = np.delete(data_inputs, test_idx, axis=0)\r\n",
        "train_labels = np.delete(data_labels, test_idx)\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ee2640addbd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m800000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 478438 is out of bounds for axis 0 with size 100"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf6eD5SiWe7L",
        "outputId": "9d9df3e1-434f-4a81-e1ea-89f1d5f04a0b"
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[455, 137,   4, ...,   0,   0,   0],\n",
              "       [  8, 789,  17, ...,   0,   0,   0],\n",
              "       [  1, 313, 352, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 35,   7, 201, ...,   0,   0,   0],\n",
              "       [113, 283, 267, ...,   0,   0,   0],\n",
              "       [113,   0,   0, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En6APsO5w9Vj"
      },
      "source": [
        "## Step 3: Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsH65ehvxAhF"
      },
      "source": [
        "class DCNN(tf.keras.Model):\r\n",
        "    \r\n",
        "    def __init__(self,\r\n",
        "                 vocab_size,\r\n",
        "                 emb_dim=128,\r\n",
        "                 nb_filters=50,\r\n",
        "                 FFN_units=512,\r\n",
        "                 nb_classes=2,\r\n",
        "                 dropout_rate=0.1,\r\n",
        "                 training=False,\r\n",
        "                 name=\"dcnn\"):\r\n",
        "        super(DCNN, self).__init__(name=name)\r\n",
        "        \r\n",
        "        self.embedding = layers.Embedding(vocab_size,emb_dim)\r\n",
        "\r\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,kernel_size=3, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4, padding=\"valid\", activation=\"relu\")\r\n",
        "        \r\n",
        "        self.pool = layers.GlobalMaxPool1D() # no training variable so we can\r\n",
        "                                             # use the same layer for each\r\n",
        "                                             # pooling step\r\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\r\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\r\n",
        "        if nb_classes == 2:\r\n",
        "            self.last_dense = layers.Dense(units=1, activation=\"sigmoid\")\r\n",
        "        else:\r\n",
        "            self.last_dense = layers.Dense(units=nb_classes, activation=\"softmax\")\r\n",
        "    \r\n",
        "    def call(self, inputs, training):\r\n",
        "        x = self.embedding(inputs)\r\n",
        "        x_1 = self.bigram(x)\r\n",
        "        x_1 = self.pool(x_1)\r\n",
        "        x_2 = self.trigram(x)\r\n",
        "        x_2 = self.pool(x_2)\r\n",
        "        x_3 = self.fourgram(x)\r\n",
        "        x_3 = self.pool(x_3)\r\n",
        "        \r\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\r\n",
        "        merged = self.dense_1(merged)\r\n",
        "        merged = self.dropout(merged, training)\r\n",
        "        output = self.last_dense(merged)\r\n",
        "        \r\n",
        "        return output"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4DzeCI961Db"
      },
      "source": [
        "## Step 4: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBaFCut46yti",
        "outputId": "162e280f-6cf9-4411-e6d8-61b49fb2e350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# Configuration details\r\n",
        "VOCAB_SIZE = tokenizer.vocab_size +1\r\n",
        "\r\n",
        "EMB_DIM = 200\r\n",
        "NB_FILTERS = 100\r\n",
        "FFN_UNITS = 256\r\n",
        "NB_CLASSES = len(set(train_labels))\r\n",
        "\r\n",
        "DROPOUT_RATE = 0.2\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "NB_EPOCHS = 2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-56fbd65fbb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Configuration details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEMB_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNB_FILTERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'vocab_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unsOdwF26y7y"
      },
      "source": [
        "# Let's train the model\r\n",
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\r\n",
        "            emb_dim=EMB_DIM,\r\n",
        "            nb_filters=NB_FILTERS,\r\n",
        "            FFN_units=FFN_UNITS,\r\n",
        "            nb_classes=NB_CLASSES,\r\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tey0ucgX9FBs"
      },
      "source": [
        "if NB_CLASSES == 2:\r\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"accuracy\"])\r\n",
        "else:\r\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\r\n",
        "                 optimizer=\"adam\",\r\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgitiq2f9TYP"
      },
      "source": [
        "checkpoint_path = \"./drive/MyDrive/DS_Projects/CNN_4_NLP/ckpt/\"\r\n",
        "\r\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\r\n",
        "\r\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\r\n",
        "\r\n",
        "if ckpt_manager.latest_checkpoint:\r\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\r\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mqDscyI-RGx"
      },
      "source": [
        "Dcnn.fit(train_inputs,\r\n",
        "         train_labels,\r\n",
        "         batch_size=BATCH_SIZE,\r\n",
        "         epochs=NB_EPOCHS)\r\n",
        "ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htndREE2_Iu0"
      },
      "source": [
        "## Step 6: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKub1syr_G5M"
      },
      "source": [
        "results = Dcnn.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE)\r\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t530OdGb_M4x"
      },
      "source": [
        "Dcnn(np.array([tokenizer.encode(\"bad teacher\")]), training=False).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GrVqSvD_S0S"
      },
      "source": [
        "# save trained model\r\n",
        "import pickle\r\n",
        "tokenizer.encode(\"bad\")\r\n",
        "filename = 'twitter_sentiment.pickle'\r\n",
        "pickle.dump(Dcnn, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyDj41RNCvdr"
      },
      "source": [
        "# load model\r\n",
        "loaded_model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}